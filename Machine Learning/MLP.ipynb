{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz1AosiUzpNye34om7nr6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JBxss/Data-Analysis/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este problema, utilizaremos una red neuronal con una capa de entrada de 2 nodos (para representar las coordenadas x e y de cada punto) y una capa de salida de 4 nodos (uno para cada cuadrante).\n",
        "\n",
        "Primero, importamos las bibliotecas necesarias:"
      ],
      "metadata": {
        "id": "Aag6tChGLb3N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZxp3B-1LU8n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, creamos un conjunto de datos de ejemplo que consta de 100 puntos aleatorios en el plano xy. Cada punto está etiquetado con el número de cuadrante correspondiente (1, 2, 3 o 4)."
      ],
      "metadata": {
        "id": "GiaJBSuyLkWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos 100 puntos aleatorios en el plano xy\n",
        "X = np.random.rand(100, 2)\n",
        "\n",
        "# Asignamos una etiqueta de cuadrante a cada punto\n",
        "y = np.zeros((100, 4))\n",
        "for i in range(100):\n",
        "    if X[i][0] >= 0.5 and X[i][1] >= 0.5:\n",
        "        y[i][0] = 1  # Cuadrante 1\n",
        "    elif X[i][0] >= 0.5 and X[i][1] < 0.5:\n",
        "        y[i][1] = 1  # Cuadrante 2\n",
        "    elif X[i][0] < 0.5 and X[i][1] < 0.5:\n",
        "        y[i][2] = 1  # Cuadrante 3\n",
        "    else:\n",
        "        y[i][3] = 1  # Cuadrante 4"
      ],
      "metadata": {
        "id": "2SBgdMsVLY5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después, dividimos los datos en conjuntos de entrenamiento y prueba:"
      ],
      "metadata": {
        "id": "6JKU5nDNLw0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test = X[:80], X[80:]\n",
        "y_train, y_test = y[:80], y[80:]"
      ],
      "metadata": {
        "id": "F3akD0osL3Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, creamos el modelo de perceptrón multicapa con una capa oculta de 10 nodos y una función de activación ReLU:"
      ],
      "metadata": {
        "id": "Qv5IsKjWL7Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el modelo de perceptrón multicapa\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "metadata": {
        "id": "etEqSdyhL_BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilamos el modelo utilizando la función de pérdida 'categorical_crossentropy' y el optimizador 'adam':"
      ],
      "metadata": {
        "id": "JsxdNIz2MEDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KlOuPzZZMOb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, entrenamos el modelo durante 100 épocas con un tamaño de lote de 10:"
      ],
      "metadata": {
        "id": "kmlrznP8MS3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xvBG-c9MXeT",
        "outputId": "2a55ac6b-380b-4a04-ca33-5ecea3980e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 31ms/step - loss: 1.3858 - accuracy: 0.1500 - val_loss: 1.3806 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3748 - accuracy: 0.1625 - val_loss: 1.3687 - val_accuracy: 0.1500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3652 - accuracy: 0.1875 - val_loss: 1.3563 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3564 - accuracy: 0.2000 - val_loss: 1.3453 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3481 - accuracy: 0.2625 - val_loss: 1.3353 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3403 - accuracy: 0.2750 - val_loss: 1.3266 - val_accuracy: 0.1500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3329 - accuracy: 0.2750 - val_loss: 1.3175 - val_accuracy: 0.1500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3248 - accuracy: 0.2750 - val_loss: 1.3089 - val_accuracy: 0.1500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3175 - accuracy: 0.2750 - val_loss: 1.2996 - val_accuracy: 0.1500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3099 - accuracy: 0.2875 - val_loss: 1.2918 - val_accuracy: 0.2000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3030 - accuracy: 0.3625 - val_loss: 1.2830 - val_accuracy: 0.2000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2943 - accuracy: 0.3750 - val_loss: 1.2745 - val_accuracy: 0.2000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2862 - accuracy: 0.3875 - val_loss: 1.2652 - val_accuracy: 0.2000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2767 - accuracy: 0.4375 - val_loss: 1.2574 - val_accuracy: 0.2500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2665 - accuracy: 0.4500 - val_loss: 1.2497 - val_accuracy: 0.2500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2570 - accuracy: 0.4750 - val_loss: 1.2424 - val_accuracy: 0.2500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2475 - accuracy: 0.4750 - val_loss: 1.2370 - val_accuracy: 0.2500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2402 - accuracy: 0.5000 - val_loss: 1.2332 - val_accuracy: 0.2500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2335 - accuracy: 0.5000 - val_loss: 1.2260 - val_accuracy: 0.2500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2269 - accuracy: 0.5000 - val_loss: 1.2215 - val_accuracy: 0.2500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2204 - accuracy: 0.5000 - val_loss: 1.2153 - val_accuracy: 0.2500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2143 - accuracy: 0.5125 - val_loss: 1.2076 - val_accuracy: 0.2500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2077 - accuracy: 0.5125 - val_loss: 1.1995 - val_accuracy: 0.2500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2020 - accuracy: 0.5125 - val_loss: 1.1944 - val_accuracy: 0.2500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1954 - accuracy: 0.5125 - val_loss: 1.1864 - val_accuracy: 0.2500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1890 - accuracy: 0.5125 - val_loss: 1.1805 - val_accuracy: 0.2500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1830 - accuracy: 0.5125 - val_loss: 1.1752 - val_accuracy: 0.2500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1764 - accuracy: 0.5125 - val_loss: 1.1688 - val_accuracy: 0.2500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1701 - accuracy: 0.5250 - val_loss: 1.1602 - val_accuracy: 0.3000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1637 - accuracy: 0.5250 - val_loss: 1.1533 - val_accuracy: 0.3500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1574 - accuracy: 0.5375 - val_loss: 1.1459 - val_accuracy: 0.4500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1510 - accuracy: 0.5375 - val_loss: 1.1408 - val_accuracy: 0.4500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1445 - accuracy: 0.5625 - val_loss: 1.1344 - val_accuracy: 0.4500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1383 - accuracy: 0.5625 - val_loss: 1.1276 - val_accuracy: 0.4500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1319 - accuracy: 0.5875 - val_loss: 1.1214 - val_accuracy: 0.4500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1256 - accuracy: 0.6000 - val_loss: 1.1156 - val_accuracy: 0.4500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1191 - accuracy: 0.6000 - val_loss: 1.1083 - val_accuracy: 0.4500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1129 - accuracy: 0.6125 - val_loss: 1.1013 - val_accuracy: 0.4500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1064 - accuracy: 0.6125 - val_loss: 1.0953 - val_accuracy: 0.4500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1006 - accuracy: 0.6250 - val_loss: 1.0882 - val_accuracy: 0.4500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0938 - accuracy: 0.6500 - val_loss: 1.0818 - val_accuracy: 0.4500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0874 - accuracy: 0.6625 - val_loss: 1.0763 - val_accuracy: 0.4500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0810 - accuracy: 0.6875 - val_loss: 1.0701 - val_accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0751 - accuracy: 0.6875 - val_loss: 1.0625 - val_accuracy: 0.5500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0686 - accuracy: 0.6875 - val_loss: 1.0565 - val_accuracy: 0.5500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0626 - accuracy: 0.6750 - val_loss: 1.0505 - val_accuracy: 0.6000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0560 - accuracy: 0.7000 - val_loss: 1.0447 - val_accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0503 - accuracy: 0.7375 - val_loss: 1.0382 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0440 - accuracy: 0.7375 - val_loss: 1.0315 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0378 - accuracy: 0.7375 - val_loss: 1.0260 - val_accuracy: 0.6000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0316 - accuracy: 0.7500 - val_loss: 1.0227 - val_accuracy: 0.6000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0256 - accuracy: 0.7500 - val_loss: 1.0178 - val_accuracy: 0.6500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0195 - accuracy: 0.7500 - val_loss: 1.0117 - val_accuracy: 0.6000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0136 - accuracy: 0.7625 - val_loss: 1.0060 - val_accuracy: 0.6000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0071 - accuracy: 0.7625 - val_loss: 0.9999 - val_accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0016 - accuracy: 0.7625 - val_loss: 0.9947 - val_accuracy: 0.6500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9952 - accuracy: 0.7625 - val_loss: 0.9888 - val_accuracy: 0.6500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9896 - accuracy: 0.7625 - val_loss: 0.9831 - val_accuracy: 0.6000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9836 - accuracy: 0.7625 - val_loss: 0.9773 - val_accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9775 - accuracy: 0.7625 - val_loss: 0.9717 - val_accuracy: 0.6500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9719 - accuracy: 0.7750 - val_loss: 0.9661 - val_accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9660 - accuracy: 0.8000 - val_loss: 0.9601 - val_accuracy: 0.6000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9599 - accuracy: 0.8000 - val_loss: 0.9554 - val_accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9542 - accuracy: 0.8000 - val_loss: 0.9513 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9485 - accuracy: 0.8000 - val_loss: 0.9456 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.8000 - val_loss: 0.9401 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9371 - accuracy: 0.8125 - val_loss: 0.9332 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9314 - accuracy: 0.8125 - val_loss: 0.9287 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9257 - accuracy: 0.8125 - val_loss: 0.9250 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9201 - accuracy: 0.8250 - val_loss: 0.9194 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9144 - accuracy: 0.8375 - val_loss: 0.9139 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9087 - accuracy: 0.8375 - val_loss: 0.9076 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9031 - accuracy: 0.8375 - val_loss: 0.9034 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8977 - accuracy: 0.8375 - val_loss: 0.8985 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8923 - accuracy: 0.8375 - val_loss: 0.8933 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8865 - accuracy: 0.8375 - val_loss: 0.8888 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8809 - accuracy: 0.8500 - val_loss: 0.8842 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.8755 - accuracy: 0.8500 - val_loss: 0.8799 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8702 - accuracy: 0.8500 - val_loss: 0.8727 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.8647 - accuracy: 0.8500 - val_loss: 0.8698 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8592 - accuracy: 0.8625 - val_loss: 0.8641 - val_accuracy: 0.8000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8537 - accuracy: 0.8625 - val_loss: 0.8595 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.8483 - accuracy: 0.8625 - val_loss: 0.8558 - val_accuracy: 0.8500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8428 - accuracy: 0.8625 - val_loss: 0.8501 - val_accuracy: 0.8000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8377 - accuracy: 0.8625 - val_loss: 0.8461 - val_accuracy: 0.8500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8322 - accuracy: 0.8625 - val_loss: 0.8410 - val_accuracy: 0.8000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.8265 - accuracy: 0.8625 - val_loss: 0.8364 - val_accuracy: 0.8000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8212 - accuracy: 0.8625 - val_loss: 0.8322 - val_accuracy: 0.8000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8162 - accuracy: 0.8625 - val_loss: 0.8259 - val_accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8109 - accuracy: 0.8625 - val_loss: 0.8213 - val_accuracy: 0.8500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8055 - accuracy: 0.8625 - val_loss: 0.8183 - val_accuracy: 0.8500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8002 - accuracy: 0.8625 - val_loss: 0.8139 - val_accuracy: 0.8500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7958 - accuracy: 0.8750 - val_loss: 0.8119 - val_accuracy: 0.8500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7899 - accuracy: 0.8750 - val_loss: 0.8066 - val_accuracy: 0.8500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7847 - accuracy: 0.8750 - val_loss: 0.8009 - val_accuracy: 0.8500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7797 - accuracy: 0.8750 - val_loss: 0.7960 - val_accuracy: 0.8500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7746 - accuracy: 0.8750 - val_loss: 0.7908 - val_accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7695 - accuracy: 0.8750 - val_loss: 0.7866 - val_accuracy: 0.8500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7653 - accuracy: 0.8750 - val_loss: 0.7844 - val_accuracy: 0.8500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7595 - accuracy: 0.8875 - val_loss: 0.7802 - val_accuracy: 0.8500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe095149f40>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, podemos evaluar la precisión del modelo en los datos de prueba:"
      ],
      "metadata": {
        "id": "S8r06xNIMcbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el modelo en los datos de prueba\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Precisión en los datos de prueba:', accuracy)\n",
        "\n",
        "# Con este modelo, podemos clasificar puntos en los 4 cuadrantes del plano xy con una precisión cercana al 100%."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKvQJQMFMiNn",
        "outputId": "f3f86917-10db-4844-89f4-5798fd66fa42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 135ms/step - loss: 0.7802 - accuracy: 0.8500\n",
            "Precisión en los datos de prueba: 0.8500000238418579\n"
          ]
        }
      ]
    }
  ]
}